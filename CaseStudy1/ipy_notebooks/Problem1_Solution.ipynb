{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 - Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib #for web scraping\n",
    "from bs4 import BeautifulSoup #for web scraping\n",
    "from pandas.io.parsers import TextParser #used in web scraping\n",
    "from lxml.html import parse #used in web scraping\n",
    "from urllib.request import urlopen #for writing csv\n",
    "import csv #for writing csv\n",
    "import pandas as pd #for dataframes\n",
    "import logging #for logging\n",
    "\n",
    "logging.basicConfig(filename='problem1_log.log', filemode='w', format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', level=logging.DEBUG)\n",
    "logging.info('Program Starting...')\n",
    "#logger = logging.getLogger()\n",
    "#logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to fetch the first URL by passing CIK and ACC_No\n",
    "- CIK and Acc_no are passed into a function. \\n\n",
    "- Leading zeroes are removed from CIK.\n",
    "- Generate the URL\n",
    "- Handles the exception when no input is given "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "url1 = \"\"\n",
    "url_pre = \"https://www.sec.gov/Archives/edgar/data/\"\n",
    "\n",
    "def geturl(cik='', accno=''):\n",
    "    if not cik or not accno:\n",
    "        logging.warning('CIK or AccNo was not given, assuming it to be 0000051143 and 0000051143-13-000007 respectively')\n",
    "        cik='0000051143'\n",
    "        accno = '0000051143-13-000007'\n",
    "        cik_striped = cik.lstrip(\"0\") #strip leading zeroes\n",
    "        accno_striped = accno.replace(\"-\",\"\")\n",
    "        url1 = url_pre + cik_striped + \"/\" + accno_striped + \"/\" + accno + \"-index.html\"\n",
    "        return url1\n",
    "    else:\n",
    "        cik_striped = cik.lstrip(\"0\") #strip leading zeroes\n",
    "        accno_striped = accno.replace(\"-\",\"\")\n",
    "        url1 = url_pre + cik_striped + \"/\" + accno_striped + \"/\" + accno + \"-index.html\"\n",
    "        return url1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.sec.gov/Archives/edgar/data/51143/000005114313000007/0000051143-13-000007-index.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geturl(\"0000051143\", \"0000051143-13-000007\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to fetch the form's URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov//Archives/edgar/data/51143/000005114313000007/ibm13q3_10q.htm\n"
     ]
    }
   ],
   "source": [
    "#page = urllib.request.urlopen(geturl(\"0000051143\", \"0000051143-13-000007\"))\n",
    "try:\n",
    "    page = urllib.request.urlopen(geturl(\"0000051143\", \"0000051143-13-000007\"))\n",
    "    \n",
    "    # parse the page and save it in soup format \n",
    "    soup = BeautifulSoup(page,\"lxml\")\n",
    "\n",
    "    # find the form name according to accession no\n",
    "    form = soup.find(id='formName').get_text()\n",
    "    formname = form[6:10]\n",
    "\n",
    "    # find the td which has the above form name\n",
    "    formtype = soup.findAll('td', text = formname)[0]\n",
    "\n",
    "    # fetch the url for that form.. Argh!!! find all siblings and then child href ? maybe\n",
    "    #formprevious = formtype.findAllPrevious\n",
    "    #print(formprevious)\n",
    "\n",
    "    url2 = \"\"\n",
    "    all_links = soup.find_all('a')\n",
    "    for link in all_links:\n",
    "        if \"10q.htm\" in link.get(\"href\"):\n",
    "            url2 = \"https://www.sec.gov/\" + link.get(\"href\")\n",
    "\n",
    "except urllib.error.HTTPError as err:\n",
    "    print(\"Invalid CIK or AccNo\")\n",
    "    logging.warning(\"Invalid CIK or AccNo\")\n",
    "    \n",
    "print(url2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the Form and fetch the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov//Archives/edgar/data/51143/000005114313000007/ibm13q3_10q.htm\n"
     ]
    }
   ],
   "source": [
    "# retrieve the web page\n",
    "print(url2)\n",
    "page_10q = urllib.request.urlopen(url2)\n",
    "soup = BeautifulSoup(page_10q,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_tables= soup.select('div[\"bclpageborder\"] table')\n",
    "#all_tables = soup.findAll('table')\n",
    "for tab in all_tables:\n",
    "    records = []\n",
    "    for tr in tab.find_all('tr'):\n",
    "        rowString=[]\n",
    "        for td in tr.findAll('td'):\n",
    "            p = td.find_all('p')\n",
    "            if len(p)>0:\n",
    "                for ps in p:\n",
    "                    ps_text = ps.get_text().replace(\"\\n\",\" \") \n",
    "                    ps_text = ps_text.replace(\"\\xa0\",\"\")                 \n",
    "                    rowString.append(ps_text)\n",
    "            else:\n",
    "                td_text=td.get_text().replace(\"\\n\",\" \")\n",
    "                td_text = td_text.replace(\"\\xa0\",\"\")\n",
    "                rowString.append(td_text)\n",
    "        records.append(rowString)        \n",
    "    with open(str(all_tables.index(tab)) + 'tables.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(records)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
